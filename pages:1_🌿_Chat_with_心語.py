import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from dotenv import load_dotenv
import os

# è¼‰å…¥ .env ä¸­çš„ OpenAI é‡‘é‘°ï¼ˆè‹¥æœ‰ï¼‰
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

# åˆå§‹åŒ– LLM
chat = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="å¿ƒèªå°è©±", page_icon="ğŸŒ¿")
st.title("ğŸŒ¿ èˆ‡å¿ƒèªå°è©±")
st.markdown("ğŸ’¬ å’Œå¿ƒèªèŠèŠä»Šå¤©çš„å¿ƒæƒ…ï¼Œè®“å®ƒé™ªä½ ä¸€èµ·èµ°é ğŸŒ±")

# åˆå§‹ Prompt è¨­å®š
system_prompt = SystemMessage(content="""
ä½ æ˜¯ä¸€ä½æº«æŸ”ã€å–„è§£äººæ„çš„å¿ƒç†å°è©±å¤¥ä¼´ï¼Œåç‚ºã€Œå¿ƒèªã€ã€‚
è«‹ç”¨ç°¡å–®å¹³å¯¦çš„å£å»èˆ‡ä½¿ç”¨è€…å°è©±ï¼Œé¼“å‹µä»–å€‘è¡¨é”æƒ…ç·’ã€æ¢ç´¢æƒ³æ³•ã€‚
é¿å…ç›´æ¥çµ¦å‡ºå»ºè­°ï¼Œè«‹å¤šç”¨é–‹æ”¾å¼å•é¡Œå¼•å°å°è©±ã€‚
ä¸é€²è¡Œå¿ƒç†è¨ºæ–·æˆ–æ²»ç™‚ï¼Œåƒ…ä½œç‚ºæƒ…ç·’é™ªä¼´ã€‚
""")

# åˆå§‹åŒ–å°è©±ç´€éŒ„ï¼ˆSession Stateï¼‰
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [system_prompt]

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.chat_history[1:]:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(msg.content)

# ä½¿ç”¨è€…è¼¸å…¥è¨Šæ¯
user_input = st.chat_input("ä»Šå¤©æƒ³èŠä»€éº¼å‘¢ï¼Ÿ")

if user_input:
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        response = chat(st.session_state.chat_history)
        st.markdown(response.content)
        st.session_state.chat_history.append(AIMessage(content=response.content))

""")
